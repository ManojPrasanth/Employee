Explain-postgres

link: http://www.dalibo.org/_media/understanding_explain.pdf
--------------------------------------------------------------
Explain:
 This command displays the execution plan that the PostgreSQL planner generates for the supplied statement.
 The execution plan shows how the table(s) referenced by the statement will be scanned — by plain sequential scan,
 index scan, etc. — and if multiple tables are referenced, what join algorithms will be used to bring together the 
 required rows from each input table.

The most critical part of the display is the estimated statement execution cost, which is the planner's guess at how
long it will take to run the statement (measured in cost units that are arbitrary, but conventionally mean disk page fetches). 
Actually two numbers are shown: the start-up cost before the first row can be returned, and the total cost to return all the rows.
For most queries the total cost is what matters, but in contexts such as a subquery in EXISTS, the planner will choose the
smallest start-up cost instead of the smallest total cost (since the executor will stop after getting one row, anyway). Also,
if you limit the number of rows to return with a LIMIT clause, the planner makes an appropriate interpolation between the 
endpoint costs to estimate which plan is really the cheapest.

The ANALYZE option causes the statement to be actually executed, not only planned. Then actual runtime statistics are added to 
the display, including the total elapsed time expended within each plan node (in milliseconds) and the total number of rows it
actually returned. This is useful for seeing whether the planner's estimates are close to reality.

Important: Keep in mind that the statement is actually executed when the ANALYZE option is used. 
Although EXPLAIN will discard any output that a SELECT would return, other side effects of the statement will happen as usual.
If you wish to use EXPLAIN ANALYZE on an INSERT, UPDATE, DELETE, CREATE TABLE AS, or EXECUTE statement without letting the command
affect your data, use this approach:

BEGIN;
EXPLAIN ANALYZE ...;
ROLLBACK;
------------------------------------------------------------------------------------------------------
create table foo (c1 integer, c2 text);

insert into foo select i, md5(random()::text) from generate_series(1, 1000000) as i;
-------------------------------------------

explain select * from foo;
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
 Seq Scan on foo  (cost=0.00..18584.82
                   rows=1025082 width=36)
• Cost
• cost to get the first row: 0.00
• cost to get all rows: 18584.82
• in “page cost” unit
• Rows
• number of rows
• Width
• average width of a row
• in bytes
------------------------------------------
analyze foo;

it is used to analyze the table and results the correct no. of rows.

What does ANALYZE do?

• It reads some random rows of the table
• 300*default_statistics_target
• It computes some statistics of the values in each column of the table
• Number of most common values, and histogram
• depends on default_statistics_target
• may be customized for each column
• And it stores the column statistics in the pg_statistic catalog
• Try the pg_stats view
• easier to read
• and lots of quite interesting informations
-----------------------------------------------
select sum(avg_width) as width from pg_stats where tablename='foo';
 width 
-------
    37
(1 row)

• Average size (in bytes) of a row in the resulting data set
• The lesser, the better
-------------------------------------------------
select reltuples from pg_class where relname='foo';
 reltuples 
-----------
     1e+06
(1 row)

• All relations metadata appear in the pg_class catalog
• Many interesting informations
• reltuples
• relpages
• relallvisible

The number of rows is easier to get. The pg_class system catalog is a catalog of all relations
(tables, indexes, sequences, etc) in the database. This catalog holds metadatas about the
relations. It also holds some statistical informations, such as the 
• estimated number of rows(column reltuples), 
• the estimated number of file pages (relpages), and 
• the number of pages containing only visibles rows for all the current transactions (relallvisible).
----------------------------------------------------------
select relpages*current_setting('seq_page_cost')::float4 + reltuples*current_setting('cpu_tuple_cost')::float4 as total_cost from pg_class where relname='foo';
 total_cost 
------------
      18334
(1 row)

select reltuples*current_setting('cpu_tuple_cost')::float4 as total_cost from pg_class where relname='foo';			//current_setting('cpu_tuple_cost')::float4=0.01
 total_cost 
------------
      10000					//(total rows/100)
(1 row)

select relpages*current_setting('seq_page_cost')::float4 as total_cost from pg_class where relname='foo';			//current_setting('seq_page_cost')::float4 as total_cost=1
 total_cost 
------------
       8334					//(estimated number of file pages (relpages))
(1 row)

---------------------------------------------------------------
explain (analyze) select * from foo;

 Seq Scan on foo  (cost=0.00..18334.00 rows=1000000 width=37) (actual time=0.020..81.148 rows=1000000 loops=1)
 Planning time: 0.060 ms
 Execution time: 116.536 ms
(3 rows)

• 3 new informations
• real execution time in milliseconds
• real number of lines
• and number of loops
• Be careful, it really executes the query!
------------------------------------------------------------------------
ANALYZE
Carry out the command and show actual run times and other statistics. This parameter defaults to FALSE.

VERBOSE
Display additional information regarding the plan. Specifically, include the output column list for each node
in the plan tree, schema-qualify table and function names, always label variables in expressions with their range table
alias, and always print the name of each trigger for which statistics are displayed. This parameter defaults to FALSE.
-------------------------------------------------------------------------
EXPLAIN verbose SELECT * FROM foo;
                             QUERY PLAN                              
---------------------------------------------------------------------
 Seq Scan on public.foo  (cost=0.00..18334.00 rows=1000000 width=37)
   Output: c1, c2
(2 rows)
---------------------------------------------------------
Be careful when using the ANALYZE option with any DML command. An EXPLAIN ANALYZE
UPDATE… will really update some rows. Same thing with DELETE, or INSERT. Be sure to enclose
them in an explicit transaction, so that you can ROLLBACk the changes.
----------------------------------------------------
Buffers:
explain (analyze,buffers) select * from foo;
                                                  QUERY PLAN                                                   
---------------------------------------------------------------------------------------------------------------
 Seq Scan on foo  (cost=0.00..18334.00 rows=1000000 width=37) (actual time=0.077..94.774 rows=1000000 loops=1)
   Buffers: shared hit=64 read=8270
 Planning time: 0.056 ms
 Execution time: 141.230 ms
(4 rows)

BUFFERS is a 9.0 feature
• New informations:
• blocks read, and written
• in the PostgreSQL cache (hit)
• and outside (read)
----------------------------------------------------------------------------------------------------------------------

postgres=# explain select * from foo where c1>501 ;
                          QUERY PLAN                          
--------------------------------------------------------------
 Seq Scan on foo  (cost=0.00..41667.00 rows=1999128 width=37)
   Filter: (c1 > 501)
(2 rows)

New line: Filter: (c1 > 500)
• Cost is higher
• less rows
• but more work because of the filtering
• Number of rows is not correct, but good enough

-----------------------------------------------------------------------------------------------
select relpages*current_setting('seq_page_cost')::float4+reltuples*current_setting('cpu_tuple_cost')::float4+reltuples*current_setting('cpu_operator_cost')::float4 as total_cost from pg_class where relname ='foo';
 total_cost 
------------
      41667
(1 row)

• The executor
• reads all the blocks of relation foo
• filters the rows according to the WHERE clause
• checks the remaining rows to make sure they are visible
---------------------------------------------------------------------------------------------------------------------------
create index on foo(c1);
CREATE INDEX
//can index data in table

set enable_seqscan to off;
// its makes force index search for explain & analyze instead of sequential search , & if table is not indexed then it will go for sequential search

set enable_seqscan to on;
// it searches based on sequential search only for all tables
---------------------------------------------------------------------------------------------------------------------------------
Adding an index with an opclass

CREATE INDEX ON foo(c2 text_pattern_ops);
EXPLAIN SELECT * FROM foo WHERE c2 LIKE 'abcd%';
QUERY PLAN
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
Bitmap Heap Scan on foo (cost=7.29..57.91
rows=100 width=37)
Filter: (c2 ~~ 'abcd%'::text)
­> Bitmap Index Scan on foo_c2_idx1
(cost=0.00..7.26 rows=13 width=0)
Index Cond: ((c2 ~>=~ 'abcd'::text)
AND (c2 ~<~ 'abce'::text))
• New kind of nodes: Bitmap Index Scan

Once there is an index with the good operator class, the planner can use the index to make the
query run faster.
-----------------------------------------------------------------------------------------------------------------------------

All the major scan nodes
• Sequential Scan
  • read all the table in sequential order
• Index Scan
  • read the index to filter on the WHERE clause
  • and the table to filter the “invisible” rows
• Bitmap Index Scan
  • the same
  • but read fully the index, and then the table
  • much quicker for a bigger number of rows
• Index Only Scan
  • for covering indexAll the major scan nodes
----------------------------------------------------------------------------------------------------------------------------
ORDER BY clause

DROP INDEX foo_c1_idx;
EXPLAIN (ANALYZE) SELECT * FROM foo ORDER BY c1;
QUERY PLAN
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
Sort
(cost=172682.84..175182.84 rows=1000000 width=37)
(actual time=612.793..729.135 rows=1000000 loops=1)
Sort Key: c1
Sort Method: external sort Disk: 45952kB
­> Seq Scan on foo (cost=0.00..18334.00
rows=1000000 width=37)
(actual time=0.017..111.068
rows=1000000 loops=1)
Total runtime: 772.685 ms

The simpler one (or the one that doesn't imply other objects than the table) is a sort done by the
CPU when executing the query. This takes CPU time and memory. In this example, it needs so
much memory that PostgreSQL does a sort on disk. It uses 45MB. As it writes many data on the
disk, it takes a lot of time. The time used to do the sequential scan (111ms) is far less than the
time to do the sorting (618ms, result of 729ms-111ms).

-----------------------------------------------------------------------------------------------------------------------------------
Are we sure it writes on the disk?

EXPLAIN (ANALYZE,BUFFERS) SELECT * FROM foo ORDER BY c1;
QUERY PLAN
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
Sort
(cost=172682.84..175182.84 rows=1000000 width=37)
(actual time=632.796..756.958 rows=1000000 loops=1)
Sort Key: c1
Sort Method: external sort Disk: 45952kB
Buffers: shared hit=3910 read=4424,
temp read=5744 written=5744
­> Seq Scan on foo (cost=0.00..18334.00
rows=1000000 width=37)
(actual time=0.134..110.617
rows=1000000 loops=1)
Buffers: shared hit=3910 read=4424
Total runtime: 811.308 ms

To make sure PostgreSQL really writes to disk the temporary data for the sort, we can use the
BUFFERS option of EXPLAIN. The interesting line here is “temp read=5744 written=5744”.
PostgreSQL wrote 5744 of temporary data, and read it. 5744 blocks of 8KB are the 45MB we were
expecting.
-------------------------------------------------------------------------------------------------------------------------------
Let's bring more mem to the sort

SET work_mem TO '200MB';
EXPLAIN (ANALYZE) SELECT * FROM foo ORDER BY c1;
QUERY PLAN
­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­­
Sort
(cost=117991.84..120491.84 rows=1000000 width=37)
(actual time=552.401..598.984 rows=1000000 loops=1)
Sort Key: c1
Sort Method: quicksort Memory: 102702kB
­> Seq Scan on foo (cost=0.00..18334.00
rows=1000000 width=37)
(actual time=0.014..102.907
rows=1000000 loops=1)
Total runtime: 637.525 ms

PostgreSQL can also do the sort in memory, but we need to give it enough memory to use. You
can do this through the work_mem parameter. By default, it's at 1MB. Here, we set it to 200MB,
and rexecute the query. PostgreSQL switches to a quicksort in-memory algorithm and that's
quicker (and it's even way quicker in 9.2, thanks to Peter Geoghegan and its use of an optimized
quicksort).
  

